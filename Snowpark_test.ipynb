{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install snowflake-snowpark-python[pandas]==1.5.0\n",
    "# !pip install snowflake-connector-python\n",
    "# !pip install snowflake-ml-python==1.0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8fe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowflake[ml]\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/46/a456b8d3ea1f03d172503166e1f3d58c67bb5b3cfd73d32bdb6c55b4d885/snowflake-0.8.0-py3-none-any.whl\n",
      "Collecting snowflake-core==0.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/55/1053b2e8e000c8aa68a6ded471a4fcc209fef77071c8d86096586a749120/snowflake_core-0.8.0-py3-none-any.whl (443kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-legacy\n",
      "  Downloading https://files.pythonhosted.org/packages/75/c9/bf69f07cf4f23fba13bd79e8e93b3b8fa7914fa8e0ef66e42332cc02b6d5/snowflake_legacy-0.8.0-py3-none-any.whl\n",
      "Collecting snowflake-ml-python==1.4.0; extra == \"ml\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/2f/8e8862f0b77c23cdcafba56be63640f87feb8aef4421116b836f40f1f9c4/snowflake_ml_python-1.4.0-py3-none-any.whl (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 46.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/73/a68704750a7679d0b6d3ad7aa8d4da8e14e151ae82e6fee774e6e0d05ec8/urllib3-2.2.1-py3-none-any.whl (121kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 57.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil>=2.8.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 47.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting atpublic>=4\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/5e/3613e5aa17ac07a69e89a5f47706f5719035f386eb024d6680483926b034/atpublic-4.1.0-py3-none-any.whl\n",
      "Collecting pydantic>=1.10.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/b9/ec44b1394957d5aa8d3a7c33f8304cd7670d10a43a286db56cec086346be/pydantic-2.7.2-py3-none-any.whl (409kB)\n",
      "\u001b[K     |████████████████████████████████| 409kB 50.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-snowpark-python<2.0.0,>=1.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/6f/fafbf56e47e2f6820ebc99203755374e20d5c26762e2de8db991f8f97579/snowflake_snowpark_python-1.18.0-py3-none-any.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 52.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<6,>=3.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/2b/a64c2d25a37aeb921fddb929111413049fc5f8b9a4c1aefaffaafe768d54/cachetools-5.3.3-py3-none-any.whl\n",
      "Collecting scipy<2,>=1.9\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f5/d0ad1a96f80962ba65e2ce1de6a1e59edecd1f0a7b55990ed208848012e0/scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6MB)\n",
      "\u001b[K     |████████████████████████████████| 38.6MB 26.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/96/43/dae06432d0c4b1dc9e9149ad37b4ca8384cf6eb7700cd9215b177b914f0a/cloudpickle-3.0.0-py3-none-any.whl\n",
      "Collecting pyarrow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/3e/9cfa78ad9744c77e4f3c183d919de3649505e50663d3715151a094c27769/pyarrow-16.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.0MB)\n",
      "\u001b[K     |████████████████████████████████| 41.0MB 3.2MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting importlib-resources<7,>=6.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/75/06/4df55e1b7b112d183f65db9503bff189e97179b256e1ea450a3c365241e0/importlib_resources-6.4.0-py3-none-any.whl\n",
      "Collecting typing-extensions<5,>=4.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/4d/d612de852a0bc64a64418e1cef25fe1914c5b1611e34cc271ed7e36174c8/typing_extensions-4.12.0-py3-none-any.whl\n",
      "Collecting sqlparse<1,>=0.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/5d/a0fdd88fd486b39ae1fd1a75ff75b4e29a0df96c0304d462fd407b82efe0/sqlparse-0.5.0-py3-none-any.whl (43kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 3.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-connector-python[pandas]<4,>=3.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/c7/608cbdbaa37e6f0dfb22d19e1fa9365c113aacc10cfd6748a148f91353d0/snowflake_connector_python-3.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5MB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xgboost<2,>=1.7.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/3a/c9c5d4d5c49b132ef15ac7b5ccf56ef1c82efe36cd19414771762e97c00e/xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3MB)\n",
      "\u001b[K     |████████████████████████████████| 200.3MB 2.8MB/s eta 0:00:01"
     ]
    }
   ],
   "source": [
    "!pip install snowflake[ml]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cbf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install snowflake-connector-python\n",
    "!pip uninstall cloudpickle -y\n",
    "!pip install cloudpickle==2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6965566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95efc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRY_DATABASE_NAME = \"MODEL_REGISTRY_SNOWSIGHT\"\n",
    "REGISTRY_SCHEMA_NAME = \"SNOWSIGHT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd38b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "def get_session():\n",
    "    parser = configparser.ConfigParser()\n",
    "    # Add the credential file name here\n",
    "    parser.read('/notebooks/notebooks/config.ini')\n",
    "\n",
    "    connection_params = dict(user=parser['Credentials']['user'], \n",
    "                         password=parser['Credentials']['password'], \n",
    "                         account=parser['Credentials']['account'], \n",
    "                         warehouse=parser['Credentials']['warehouse'], \n",
    "                         database=REGISTRY_DATABASE_NAME,\n",
    "                         schema=REGISTRY_SCHEMA_NAME, \n",
    "                         role=parser['Credentials']['role'])\n",
    "#     print(\"connection_params = \",  connection_params)\n",
    "\n",
    "\n",
    "    session = Session.builder.configs(connection_params).create()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2319ac22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.session.Session at 0x7e78ac481cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = get_session()\n",
    "# session.close()\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c401604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.registry import Registry as model_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49192969",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep -i cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffad949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_registry.create_model_registry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = model_registry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6835e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# registry = model_registry.ModelRegistry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = registry.show_models()\n",
    "df\n",
    "# type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2d25d",
   "metadata": {},
   "source": [
    "# Get model list from snowpark registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a32df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = registry.models()\n",
    "model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adca9b9a",
   "metadata": {},
   "source": [
    "# Get model details from registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb27a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m =registry.get_model(\"my_model\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4496f60",
   "metadata": {},
   "source": [
    "# Get model versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_version = m.show_versions()\n",
    "df_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf87c3",
   "metadata": {},
   "source": [
    "# Set default model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_version = m.default\n",
    "m.default = \"V1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863c652",
   "metadata": {},
   "source": [
    "# Get default model version details from model-registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = m.default\n",
    "mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a006d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load default vesion as python object\n",
    "# clf = mv.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1e616",
   "metadata": {},
   "source": [
    "# Run prediction on scikit-learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [[ 25, 185,  88,  78,  65,  81,  77,  75,  81,  63,  37,  26,   9, 10,  79,  82]]\n",
    "data_array = np.asarray(data_list)\n",
    "print(\"data_array =\", data_array)\n",
    "\n",
    "remote_prediction = mv.run(data_array, function_name=\"predict\")\n",
    "remote_prediction   # assuming test_features is Snowpark DataFrame\n",
    "remote_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4cbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cloudpickle\n",
    "\n",
    "# model_obj = cloudpickle.load(open(\"/notebooks/notebooks/ml_model\", \"rb\"))\n",
    "# model_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fe843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = cloudpickle.load(open(\"/notebooks/notebooks/x_train\", \"rb\"))\n",
    "# x_train\n",
    "# type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61facf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c700bc4",
   "metadata": {},
   "source": [
    "# Deploy model with custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b194ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.model import custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExamplePipelineModel(custom_model.CustomModel):\n",
    "#     def __init__(self, context: ModelContext) -> None:\n",
    "#         super().__init__(context)\n",
    "#         v = int(open(context.path('config')).read())\n",
    "#         self.bias = json.loads(v)['bias']\n",
    "\n",
    "    @custom_model.inference_api\n",
    "    def run(self, data_list: list) -> pd.DataFrame:\n",
    "#         features = self.context.model_ref('feature_preproc').transform(input)\n",
    "#         model_output = self.context.model_ref('m2').predict(\n",
    "#             self.context.model_ref('m1').predict(features)\n",
    "#         )\n",
    "#         return pd.DataFrame({\n",
    "#             'output': model_output + self.bias})\n",
    "        data_array = np.asarray(data_list)\n",
    "        try:\n",
    "            prediction = model.predict(data_array)\n",
    "        except:\n",
    "            prediction = model.predict(data_array.reshape(1, -1))\n",
    "        return prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9902a57",
   "metadata": {},
   "source": [
    "# Train & register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32311ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"/data/fifa.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['age','height_cm','weight_kg','skill_dribbling','attacking_crossing','attacking_finishing','movement_acceleration','movement_sprint_speed','power_shot_power','mentality_aggression','defending_marking','defending_standing_tackle','goalkeeping_diving','goalkeeping_handling','overall','potential']]\n",
    "y = data['value_eur']\n",
    "ylog = np.log(y)\n",
    "\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(ylog, bins='auto')\n",
    "# plt.title(\"ln(value_eur)\")\n",
    "# plt.show()\n",
    "\n",
    "X_train, X_test, ylog_train, ylog_test, y_train, y_test = train_test_split(X, ylog, y, test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ee341",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_default = GradientBoostingRegressor()\n",
    "gbm_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = registry.log_model(gbm_default,\n",
    "                   model_name=\"my_model\",\n",
    "                   version_name=\"v2\",\n",
    "                   conda_dependencies=[\"scikit-learn\", \"cloudpickle\"],\n",
    "                   comment=\"My awesome ML model\",\n",
    "#                     python_version=\"3.9\",\n",
    "#                    metrics={\"score\": 96},\n",
    "                   sample_input_data=x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e12c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dumps(obj, file_path):\n",
    "    import cloudpickle\n",
    "    out = open(file_path, \"wb\")\n",
    "    cloudpickle.dump(obj, out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dumps(gbm_default, \"/notebooks/notebooks/ml_model_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81eaa4f",
   "metadata": {},
   "source": [
    "# Create stage in snowflake-model-registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ae139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"\n",
    "#         create or replace stage sample_model_serving_udf_stg\n",
    "#         directory = (enable = true)\n",
    "#         copy_options = (on_error='skip_file')\n",
    "#         \"\"\"\n",
    "\n",
    "# session.sql(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36420f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"created_on\"                      |\"name\"     |\"database_name\"           |\"schema_name\"  |\"url\"  |\"has_credentials\"  |\"has_encryption_key\"  |\"owner\"  |\"comment\"  |\"region\"  |\"type\"    |\"cloud\"  |\"notification_channel\"  |\"storage_integration\"  |\"endpoint\"  |\"owner_role_type\"  |\"directory_enabled\"  |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|2024-05-23 05:38:13.276000-07:00  |ML_MODELS  |MODEL_REGISTRY_SNOWSIGHT  |SNOWSIGHT      |       |N                  |N                     |PRAKHAR  |           |NULL      |INTERNAL  |NULL     |NULL                    |NULL                   |NULL        |ROLE               |Y                    |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see the stages\n",
    "session.sql(\"show stages\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f1d9a9",
   "metadata": {},
   "source": [
    "# Upload model file on ML_MODELS stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the stage for storing the ML models\n",
    "# session.sql(\"USE MODEL_REGISTRY_SNOWSIGHT;\")\n",
    "session.sql('CREATE OR REPLACE STAGE ML_MODELS').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36eb0de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='ml_model_2', target='ml_model_2', source_size=129477, target_size=129488, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.file.put(\n",
    "    \"/notebooks/notebooks/ml_model_2\", \"@ML_MODELS\", auto_compress=False, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b6da7",
   "metadata": {},
   "source": [
    "# Read model file from stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "899bfbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "\n",
    "#Register above uploded model as import of UDF\n",
    "session.add_import(\"@ML_MODELS/ml_model_2\")\n",
    "\n",
    "#map packege dependancies\n",
    "session.add_packages(\"scikit-learn\", \"pandas\", \"cloudpickle==2.2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import PandasSeries, PandasDataFrame\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    import cloudpickle\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    #where all imports located at\n",
    "    import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "\n",
    "    if import_dir:\n",
    "        with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "            m = cloudpickle.load(file)\n",
    "            return m\n",
    "\n",
    "#register UDF\n",
    "@F.udf(name = 'get_model_from_file', is_permanent = True, replace = True, stage_location = '@ML_MODELS')\n",
    "def get_model_from_file(data_list: list) -> list:\n",
    "    import numpy as np\n",
    "    \n",
    "    # later we will input train data as JSON object\n",
    "    # hance, we have to convert JSON object as pandas DF\n",
    "    data_array = np.asarray(data_list)\n",
    "    pipeline = read_file('ml_model_2')\n",
    "    \n",
    "    return \"test\"\n",
    "#     return pipeline.predict(data_array).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f3dc5",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
