{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install snowflake-snowpark-python[pandas]==1.5.0\n",
    "# !pip install snowflake-connector-python\n",
    "# !pip install snowflake-ml-python==1.0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake[ml]==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cbf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install snowflake-connector-python\n",
    "!pip uninstall cloudpickle -y\n",
    "!pip install cloudpickle==2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6965566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95efc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRY_DATABASE_NAME = \"MODEL_REGISTRY_SNOWSIGHT\"\n",
    "REGISTRY_SCHEMA_NAME = \"SNOWINSIGHT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd38b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "def get_session():\n",
    "    parser = configparser.ConfigParser()\n",
    "    # Add the credential file name here\n",
    "    parser.read('/notebooks/notebooks/config.ini')\n",
    "\n",
    "    connection_params = dict(user=parser['Credentials']['user'], \n",
    "                         password=parser['Credentials']['password'], \n",
    "                         account=parser['Credentials']['account'], \n",
    "                         warehouse=parser['Credentials']['warehouse'], \n",
    "                         database=REGISTRY_DATABASE_NAME,\n",
    "                         schema=REGISTRY_SCHEMA_NAME, \n",
    "                         role=parser['Credentials']['role'])\n",
    "#     print(\"connection_params = \",  connection_params)\n",
    "\n",
    "\n",
    "    session = Session.builder.configs(connection_params).create()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2319ac22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.session.Session at 0x7b3329764f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = get_session()\n",
    "# session.close()\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c401604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.registry import Registry as model_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49192969",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep -i sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a8c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"LIST STAGES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffad949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_registry.create_model_registry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "721b2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = model_registry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6835e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# registry = model_registry.ModelRegistry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = registry.show_models()\n",
    "df\n",
    "# type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2d25d",
   "metadata": {},
   "source": [
    "# Get model list from snowpark registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a32df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = registry.models()\n",
    "model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adca9b9a",
   "metadata": {},
   "source": [
    "# Get model details from registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb27a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m =registry.get_model(\"sample_sklearn_model\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4496f60",
   "metadata": {},
   "source": [
    "# Get model versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_version = m.show_versions()\n",
    "df_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf87c3",
   "metadata": {},
   "source": [
    "# Set default model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_version = m.default\n",
    "m.default = \"V1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863c652",
   "metadata": {},
   "source": [
    "# Get default model version details from model-registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = m.default\n",
    "mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a006d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load default vesion as python object\n",
    "# clf = mv.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1e616",
   "metadata": {},
   "source": [
    "# Run prediction on scikit-learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_list = [[ 25, 185,  88,  78,  65,  81,  77,  75,  81,  63,  37,  26,   9, 10,  79,  82]]\n",
    "data_array = np.asarray(data_list)\n",
    "print(\"data_array =\", data_array)\n",
    "\n",
    "remote_prediction = mv.run(data_array, function_name=\"predict\")\n",
    "remote_prediction   # assuming test_features is Snowpark DataFrame\n",
    "remote_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4cbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cloudpickle\n",
    "\n",
    "# model_obj = cloudpickle.load(open(\"/notebooks/notebooks/ml_model\", \"rb\"))\n",
    "# model_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fe843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = cloudpickle.load(open(\"/notebooks/notebooks/x_train\", \"rb\"))\n",
    "# x_train\n",
    "# type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61facf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c700bc4",
   "metadata": {},
   "source": [
    "# Deploy model with custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b194ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.model import custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExamplePipelineModel(custom_model.CustomModel):\n",
    "#     def __init__(self, context: ModelContext) -> None:\n",
    "#         super().__init__(context)\n",
    "#         v = int(open(context.path('config')).read())\n",
    "#         self.bias = json.loads(v)['bias']\n",
    "\n",
    "    @custom_model.inference_api\n",
    "    def run(self, data_list: list) -> pd.DataFrame:\n",
    "#         features = self.context.model_ref('feature_preproc').transform(input)\n",
    "#         model_output = self.context.model_ref('m2').predict(\n",
    "#             self.context.model_ref('m1').predict(features)\n",
    "#         )\n",
    "#         return pd.DataFrame({\n",
    "#             'output': model_output + self.bias})\n",
    "        data_array = np.asarray(data_list)\n",
    "        try:\n",
    "            prediction = model.predict(data_array)\n",
    "        except:\n",
    "            prediction = model.predict(data_array.reshape(1, -1))\n",
    "        return prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9902a57",
   "metadata": {},
   "source": [
    "# Train & register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32311ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"/data/fifa.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fb05b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['age','height_cm','weight_kg','skill_dribbling','attacking_crossing','attacking_finishing','movement_acceleration','movement_sprint_speed','power_shot_power','mentality_aggression','defending_marking','defending_standing_tackle','goalkeeping_diving','goalkeeping_handling','overall','potential']]\n",
    "y = data['value_eur']\n",
    "ylog = np.log(y)\n",
    "\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(ylog, bins='auto')\n",
    "# plt.title(\"ln(value_eur)\")\n",
    "# plt.show()\n",
    "\n",
    "X_train, X_test, ylog_train, ylog_test, y_train, y_test = train_test_split(X, ylog, y, test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ee341",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_default = GradientBoostingRegressor()\n",
    "gbm_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1aa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "def dump_model(model, path):\n",
    "    joblib.dump(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82918f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_model(gbm_default, \"/notebooks/notebooks/ml_model_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c04762",
   "metadata": {},
   "source": [
    "# Generating model signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.model import model_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b236538",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = model_signature.infer_signature(\n",
    "    X_train.head(),\n",
    "    data['value_eur'],\n",
    "    input_feature_names=['age','height_cm','weight_kg','skill_dribbling',\n",
    "                         'attacking_crossing','attacking_finishing','movement_acceleration',\n",
    "                         'movement_sprint_speed','power_shot_power','mentality_aggression',\n",
    "                         'defending_marking','defending_standing_tackle','goalkeeping_diving',\n",
    "                         'goalkeeping_handling','overall','potential'],\n",
    "    output_feature_names=['value_eur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = registry.log_model(gbm_default,\n",
    "                   model_name=\"sample_sklearn_model_4\",\n",
    "                   version_name=\"v1\",\n",
    "                   conda_dependencies=[\"scikit-learn==1.3.2\", \"scipy==1.13.1\", \"cloudpickle==2.2.1\"],\n",
    "                   comment=\"My awesome ML model\",\n",
    "                    python_version=\"3.9.19\",\n",
    "                   metrics={\"score\": 96},\n",
    "                   sample_input_data=X_train\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e12c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "def dump_model(model, path):\n",
    "    joblib.dump(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_model(gbm_default, \"/notebooks/notebooks/ml_model_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81eaa4f",
   "metadata": {},
   "source": [
    "# Create stage in snowflake-model-registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ae139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"\n",
    "#         create or replace stage sample_model_serving_udf_stg\n",
    "#         directory = (enable = true)\n",
    "#         copy_options = (on_error='skip_file')\n",
    "#         \"\"\"\n",
    "\n",
    "# session.sql(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36420f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the stages\n",
    "session.sql(\"show stages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.files import SnowflakeFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "with SnowflakeFile.open(\"@STG_ML_MODELS/ml_model_2\") as file:\n",
    "    m= cloudpickle.load(file)\n",
    "    print(type(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f1d9a9",
   "metadata": {},
   "source": [
    "# Upload model file on ML_MODELS stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the stage for storing the ML models\n",
    "# session.sql(\"USE MODEL_REGISTRY_SNOWSIGHT;\")\n",
    "session.sql('CREATE OR REPLACE STAGE STG_ML_MODELS').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.file.put(\n",
    "    X_train.to_csv(), \"@STG_ML_MODELS\", auto_compress=False, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb0de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.file.put(\n",
    "    \"/notebooks/notebooks/ml_model_4\", \"@STG_ML_MODELS\", auto_compress=False, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b6da7",
   "metadata": {},
   "source": [
    "# Read model file from stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bfbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "\n",
    "#Register above uploded model as import of UDF\n",
    "session.add_import(\"@STG_ML_MODELS/ml_model_2\")\n",
    "\n",
    "#map packege dependancies\n",
    "session.add_packages(\"scikit-learn\", \"pandas\", \"cloudpickle==2.2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import PandasSeries, PandasDataFrame\n",
    "import snowflake.snowpark.functions as F\n",
    "from typing import  Optional\n",
    "\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    import cloudpickle\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    #where all imports located at\n",
    "    import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "\n",
    "    if import_dir:\n",
    "        with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "            m = cloudpickle.load(file)\n",
    "            return m\n",
    "\n",
    "#register UDF\n",
    "@F.udf(name = 'READ_MODEL_FROM_FILE', is_permanent = True, replace = True, stage_location = '@STG_ML_MODELS')\n",
    "def read_model_from_file(file_name:Optional[str]) -> str:\n",
    "    import numpy as np\n",
    "    \n",
    "    # later we will input train data as JSON object\n",
    "    # hance, we have to convert JSON object as pandas DF\n",
    "    data_array = np.asarray(data_list)\n",
    "    pipeline = read_file(file_name)\n",
    "    print(\"type of pickle object =\", type(pipeline))\n",
    "#     dict_mod[\"model_obj\"] = pipeline\n",
    "    return \"pipeline\"\n",
    "#     return pipeline.predict(data_array).to_list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @F.udf(name = 'READ_MODEL_FROM_FILE', is_permanent = True, replace = True, stage_location = '@STG_ML_MODELS')\n",
    "# def read_model_from_file(file_name:Optional[str]) -> str:\n",
    "#     import numpy as np\n",
    "    \n",
    "#     # later we will input train data as JSON object\n",
    "#     # hance, we have to convert JSON object as pandas DF\n",
    "#     data_array = np.asarray(data_list)\n",
    "#     pipeline = read_file(file_name)\n",
    "#     print(\"type of pickle object =\", type(pipeline))\n",
    "# #     dict_mod[\"model_obj\"] = pipeline\n",
    "#     return pipeline\n",
    "# #     return pipeline.predict(data_array).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deae998",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"DESC FUNCTION READ_MODEL_FROM_FILE(\"ml_model\")\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac767dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_udf = read_model_from_file(\"ml_model_2\")\n",
    "# model_udf = read_file(\"ml_model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86657f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_obj = joblib.load(read_model_from_file(\"ml_model_2\"))\n",
    "import os\n",
    "model_file = os.path.join(\"/notebooks/notebooks\", \"ml_model_3\")\n",
    "model_obj = joblib.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ed953",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"/data/X_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe078460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a10e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [[ 25, 185,  88,  78,  65,  81,  77,  75,  81,  63,  37,  26,   9, 10,  79,  82]]\n",
    "data_array = np.asarray(data_list)\n",
    "print(\"data_array =\", data_array)\n",
    "\n",
    "remote_prediction = model_obj.run(data_array, function_name=\"predict\")\n",
    "remote_prediction   # assuming test_features is Snowpark DataFrame\n",
    "remote_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d312ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374bf208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65091fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import Variant\n",
    "def read_model_from_stage(session: Session, df_dict: dict) -> Variant:\n",
    "\n",
    "    # print(\"file_name =\", file_name)\n",
    "    # session.add_import(\"@STG_ML_MODELS/\"+file_name)\n",
    "    # map packege dependancies\n",
    "    # session.add_packages(\"scikit-learn\", \"pandas\", \"cloudpickle==2.2.1\")\n",
    "\n",
    "\n",
    "\n",
    "    # from snowflake.snowpark.types import PandasSeries, PandasDataFrame\n",
    "    # import snowflake.snowpark.functions as F\n",
    "    # from typing import Optional\n",
    "    from snowflake.snowpark.files import SnowflakeFile\n",
    "    from snowflake.ml.registry.registry import Registry\n",
    "\n",
    "    import joblib\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    print(\"df ===\", df)\n",
    "\n",
    "    model_file = '@STG_ML_MODELS/ml_model_4'\n",
    "    # Specify 'mode = rb' to open the file in binary mode.\n",
    "    with SnowflakeFile.open(model_file, 'rb', require_scoped_url=False) as f:\n",
    "        model_obj = joblib.load(f)\n",
    "        # return str(model_obj)\n",
    "        # return str(model_obj)\n",
    "\n",
    "        reg = Registry(session=session)\n",
    "\n",
    "        mv = reg.log_model(model=model_obj,\n",
    "                           model_name=\"sample_model\",\n",
    "                           comment=\"test\",\n",
    "                           version_name=\"run1\",\n",
    "                           python_version=\"3.9.19\",\n",
    "                           conda_dependencies=[\"scikit-learn==1.3.2\"],\n",
    "                           metrics={\"model_metrics\": {\"score\": 96}, \"project_id\": \"0001\", \"type\": \"Model\"},\n",
    "                           sample_input_data=df\n",
    "                           )\n",
    "\n",
    "        print(\"model got registered successfully\")\n",
    "        return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sproc.register(func=read_model_from_stage,\n",
    "                           name=\"read_model_from_stage\",\n",
    "                           packages=[\"snowflake-snowpark-python\", \"snowflake-ml-python\",\"scikit-learn\", \"pandas\", \"cloudpickle==2.2.1\", \"joblib\"],\n",
    "                           isPermanant=True,\n",
    "                           stage_location=\"@STG_ML_MODELS\",\n",
    "                           replace=True,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = X_train.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bb6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8fc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = session.call(\"read_model_from_stage\", dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81fa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2dd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f21c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/e5/79a62e5c9c9ddbfa9ff5222240d408c1eeea4e38741a0dc8343edc7ef1ec/category_encoders-2.6.3-py2.py3-none-any.whl (81kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn>=0.20.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ea/44b8c639afe93c0b55d7f0852b663d18623132a6879516afe0380fa743b6/scikit_learn-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4MB 2.8MB/s eta 0:00:01     |███████████████████████████████▌| 13.2MB 2.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.14.0\n",
      "  Using cached https://files.pythonhosted.org/packages/54/30/c2a907b9443cf42b90c17ad10c1e8fa801975f01cb9764f3f8eb8aea638b/numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting scipy>=1.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/35/f5/d0ad1a96f80962ba65e2ce1de6a1e59edecd1f0a7b55990ed208848012e0/scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting statsmodels>=0.9.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/54/4c8086e90a54b8e57ac8ad63fc38eea20aa6507fb975efdb6c72210744c9/statsmodels-0.14.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8MB)\n",
      "\u001b[K     |████████████████████████████████| 10.8MB 12.2MB/s eta 0:00:01    |▉                               | 276kB 12.2MB/s eta 0:00:01     |█████▍                          | 1.8MB 12.2MB/s eta 0:00:01     |███████▌                        | 2.5MB 12.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=1.0.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/30/f6f1f1ac36250f50c421b1b6af08c35e5a8b5a84385ef928625336b93e6f/pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1MB 2.0MB/s eta 0:00:01   |▏                               | 81kB 4.3MB/s eta 0:00:04     |█▊                              | 716kB 2.0MB/s eta 0:00:07\n",
      "\u001b[?25hCollecting patsy>=0.5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/f3/1d311a09c34f14f5973bb0bb0dc3a6e007e1eda90b5492d082689936ca51/patsy-0.5.6-py2.py3-none-any.whl (233kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 20.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Using cached https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl\n",
      "Collecting packaging>=21.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/df/1fceb2f8900f8639e278b056416d49134fb8d84c5942ffaa01ad34782422/packaging-24.0-py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Using cached https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl\n",
      "Collecting tzdata>=2022.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl (345kB)\n",
      "\u001b[K     |████████████████████████████████| 348kB 33.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "\u001b[31mERROR: refractio 2.1.5.2 has requirement pandas==2.0.0, but you'll have pandas 2.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-utils 1.0.2 has requirement scikit-learn==1.2.1; python_version >= \"3.8\", but you'll have scikit-learn 1.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mlflow 2.6.0 has requirement packaging<24, but you'll have packaging 24.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mlflow 2.6.0 has requirement pytz<2024, but you'll have pytz 2024.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.4.0 has requirement packaging<24,>=20.9, but you'll have packaging 24.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.4.0 has requirement pandas<2,>=1.0.0, but you'll have pandas 2.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.4.0 has requirement scikit-learn<1.4,>=1.2.1, but you'll have scikit-learn 1.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.4.0 has requirement xgboost<2,>=1.7.3, but you'll have xgboost 2.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-connector-python 3.10.1 has requirement urllib3<2.0.0,>=1.21.1; python_version < \"3.10\", but you'll have urllib3 2.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: botocore 1.34.106 has requirement urllib3<1.27,>=1.25.4; python_version < \"3.10\", but you'll have urllib3 2.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: openapi-schema-validator 0.6.2 has requirement jsonschema<5.0.0,>=4.19.1, but you'll have jsonschema 4.19.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement Flask==2.1.1; python_version >= \"3.7\", but you'll have flask 2.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement itsdangerous==2.0.1, but you'll have itsdangerous 2.1.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement Jinja2==3.0.3, but you'll have jinja2 3.1.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement matplotlib==3.6.0; python_version >= \"3.8\", but you'll have matplotlib 3.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-client 1.0.0 has requirement matplotlib==3.1.1, but you'll have matplotlib 3.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.7.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, scipy, threadpoolctl, joblib, scikit-learn, packaging, six, patsy, pytz, python-dateutil, tzdata, pandas, statsmodels, category-encoders\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5de26f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'category_encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcategory_encoders\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mce\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'category_encoders'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import requests\n",
    "# from refractml import *\n",
    "# from refractml.constants import MLModelFlavours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc30b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"/data/car_new.csv\")\n",
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdcc306",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = cars['class_num']\n",
    "X = cars.drop (['class_num'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.18, shuffle=True, random_state=25)\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dbe554",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tree = DecisionTreeClassifier()\n",
    "model=first_tree.fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "first_tree.score(X_test, y_test)\n",
    "y_prob = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_train.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f3dc5",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
