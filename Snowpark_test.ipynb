{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install snowflake-snowpark-python[pandas]==1.5.0\n",
    "# !pip install snowflake-connector-python\n",
    "# !pip install snowflake-ml-python==1.0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake[ml]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cbf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install snowflake-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6965566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd38b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "def get_session():\n",
    "    parser = configparser.ConfigParser()\n",
    "    # Add the credential file name here\n",
    "    parser.read('/notebooks/notebooks/config.ini')\n",
    "\n",
    "    connection_params = dict(user=parser['Credentials']['user'], \n",
    "                         password=parser['Credentials']['password'], \n",
    "                         account=parser['Credentials']['account'], \n",
    "                         warehouse=parser['Credentials']['warehouse'], \n",
    "                         database=REGISTRY_DATABASE_NAME,\n",
    "                         schema=REGISTRY_SCHEMA_NAME, \n",
    "                         role=parser['Credentials']['role'])\n",
    "#     print(\"connection_params = \",  connection_params)\n",
    "\n",
    "\n",
    "    session = Session.builder.configs(connection_params).create()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2319ac22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.session.Session at 0x7e808e214790>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = get_session()\n",
    "# session.close()\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95efc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRY_DATABASE_NAME = \"MODEL_REGISTRY_SNOWSIGHT\"\n",
    "REGISTRY_SCHEMA_NAME = \"SNOWSIGHT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c401604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.registry import Registry as model_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49192969",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep -i cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffad949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry.create_model_registry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = model_registry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6835e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# registry = model_registry.ModelRegistry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = registry.show_models()\n",
    "df\n",
    "# type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a32df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = registry.models()\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb27a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m =registry.get_model(\"my_model\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_version = m.show_versions()\n",
    "df_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_version = m.default\n",
    "m.default = \"V2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = m.default\n",
    "mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a006d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load default vesion as python object\n",
    "# clf = mv.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [ 25, 185,  88,  78,  65,  81,  77,  75,  81,  63,  37,  26,   9,\n",
    "        10,  79,  82]\n",
    "data_array = np.asarray(data_list)\n",
    "\n",
    "remote_prediction = mv.run(data_array, function_name=\"predict\")\n",
    "remote_prediction   # assuming test_features is Snowpark DataFrame\n",
    "remote_prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4cbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cloudpickle\n",
    "\n",
    "# model_obj = cloudpickle.load(open(\"/notebooks/notebooks/ml_model\", \"rb\"))\n",
    "# model_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fe843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = cloudpickle.load(open(\"/notebooks/notebooks/x_train\", \"rb\"))\n",
    "# x_train\n",
    "# type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61facf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = registry.log_model(gbm_default,\n",
    "                   model_name=\"my_model\",\n",
    "                   version_name=\"v2\",\n",
    "                   conda_dependencies=[\"scikit-learn\", \"cloudpickle\"],\n",
    "                   comment=\"My awesome ML model\",\n",
    "#                     python_version=\"3.9\",\n",
    "#                    metrics={\"score\": 96},\n",
    "                   sample_input_data=x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32311ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"/data/fifa.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['age','height_cm','weight_kg','skill_dribbling','attacking_crossing','attacking_finishing','movement_acceleration','movement_sprint_speed','power_shot_power','mentality_aggression','defending_marking','defending_standing_tackle','goalkeeping_diving','goalkeeping_handling','overall','potential']]\n",
    "y = data['value_eur']\n",
    "ylog = np.log(y)\n",
    "\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(ylog, bins='auto')\n",
    "# plt.title(\"ln(value_eur)\")\n",
    "# plt.show()\n",
    "\n",
    "X_train, X_test, ylog_train, ylog_test, y_train, y_test = train_test_split(X, ylog, y, test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ee341",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_default = GradientBoostingRegressor()\n",
    "gbm_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81eaa4f",
   "metadata": {},
   "source": [
    "# Create stage in snowflake-model-registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ae139",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        create or replace stage sample_model_serving_udf_stg\n",
    "        directory = (enable = true)\n",
    "        copy_options = (on_error='skip_file')\n",
    "        \"\"\"\n",
    "\n",
    "session.sql(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36420f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"created_on\"                      |\"name\"     |\"database_name\"           |\"schema_name\"  |\"url\"  |\"has_credentials\"  |\"has_encryption_key\"  |\"owner\"  |\"comment\"  |\"region\"  |\"type\"    |\"cloud\"  |\"notification_channel\"  |\"storage_integration\"  |\"endpoint\"  |\"owner_role_type\"  |\"directory_enabled\"  |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|2024-05-23 05:38:13.276000-07:00  |ML_MODELS  |MODEL_REGISTRY_SNOWSIGHT  |SNOWSIGHT      |       |N                  |N                     |PRAKHAR  |           |NULL      |INTERNAL  |NULL     |NULL                    |NULL                   |NULL        |ROLE               |N                    |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see the stages\n",
    "session.sql(\"show stages\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc77c3",
   "metadata": {},
   "source": [
    "# Upload model file on ML_MODELS stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08e6689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "|\"status\"                                    |\n",
      "----------------------------------------------\n",
      "|Stage area ML_MODELS successfully created.  |\n",
      "----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create the stage for storing the ML models\n",
    "# session.sql(\"USE MODEL_REGISTRY_SNOWSIGHT;\")\n",
    "session.sql('CREATE OR REPLACE STAGE ML_MODELS').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d35f718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='ml_model', target='ml_model', source_size=170156, target_size=170160, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.file.put(\n",
    "    \"/notebooks/notebooks/ml_model\", \"@ML_MODELS\", auto_compress=False, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6e9ebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    }
   ],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "\n",
    "#Register above uploded model as import of UDF\n",
    "session.add_import(\"@ML_MODELS/ml_model\")\n",
    "\n",
    "#map packege dependancies\n",
    "session.add_packages(\"scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import PandasSeries, PandasDataFrame\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    import cloudpickle\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    #where all imports located at\n",
    "    import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "\n",
    "    if import_dir:\n",
    "        with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "            m = cloudpickle.load(file)\n",
    "            return m\n",
    "\n",
    "#register UDF\n",
    "@F.udf(name = 'predict_score', is_permanent = True, replace = True, stage_location = '@ML_MODELS')\n",
    "def predict_score(ds: list) -> list:\n",
    "    \n",
    "    # later we will input train data as JSON object\n",
    "    # hance, we have to convert JSON object as pandas DF\n",
    "    df = pd.io.json.json_normalize(ds)[feature_cols]\n",
    "    pipeline = read_file('ml_model')\n",
    "    return pipeline.predict(df)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f3dc5",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
